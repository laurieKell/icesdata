---
title: "ICES Stocks - Nonstationary Methods"
author: "L Kell"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ICES Stocks - Nonstationary Methods}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
  %\VignetteEncoding{UTF-8}
bibliography: refs.bib
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  eval = TRUE,
  cache = TRUE,
  cache.path = "cache/nonstationary-methods-",
  fig.path = "figures/nonstationary-methods-",
  fig.width = 10,
  fig.height = 12,
  dev = "png"
)

iFig = 0
iTab = 0
```

```{r, libraries}
# Load icesdata package
library(icesdata)

# Load FLR ecosystem packages
library(FLCore)
library(FLBRP)
library(FLife)
library(FLCandy)
library(FLRebuild)

# Load data manipulation packages
library(plyr)

# Load visualization packages
library(ggplot2)
library(scales)

# Set default theme for all plots
theme_set(theme_ices(base_size = 12))

# Load parallel processing
  library(doParallel)
  library(foreach)
  library(parallel)
```

## Introduction

ICES Category 1 stock assessments, analytical age based assessments that have been benchmarked.

**Note:** This vignette requires FLCandy package from the **refactored** branch:
```r
devtools::install_github("lauriekell/FLCandy", ref = "refactored")
```

```{r, data-load}
# Load all ICES data
load_all_ices_data()

# Set up vignette data directory for saving outputs
vignetteDataDir = get_vignette_output_dir()
```

### Summaries

Biological assumptions and variation by age, and year 

```{r, vary}
# Check parameter variation using package function
vary = checkVariation(icesdata)

vary = transform(vary,
  mByAge = ifelse(mAge, "M varys by Age", "M constant by Age"),
  mByYr = ifelse(mYr, "M varys by Year", "M constant by Year"),
  matByYr = ifelse(matYr, "Mat varys by Year", "Mat constant by Year"),
  massByYr = ifelse(massYr, "Mass varys by Year", "Mass constant by Year")
  )
  
  # Save to vignette data directory
save(vary, file = file.path(vignetteDataDir, "vary.RData"))
```

### Equilibrium Analysis

Take the average values-at-age across all years for each stock, and fit a 
Beverton and Holt stock recruitment relationship using steepness from `FishBase`.

This section fits equilibrium models (SRR) for each stock using different scenarios:
- Beverton-Holt models: without priors (bh1), with steepness prior (bh2), with R0 fixed (bh3)
- Ricker models: without priors (rk1), with steepness prior (rk2), with R0 fixed (rk3)

```{r, srr}
ids = names(icesdata)

# Extract FishLife parameters and benchmark reference points
fl = fishlife(icesdata)
bm = benchmark(icesdata)

# Fit segreg models for R0 calculation
sgs = FLBRPs(plyr::llply(icesdata, FLCandy::eql, model = "segreg"))

# Calculate geometric mean for segreg models
gms = plyr::llply(sgs, function(x) {
  model(x) = geomean()$model
  params(x)["a"] = params(x)["a"] %*% params(x)["b"]
  params(x) = params(x)[1]
  brp(x)
})

# Extract R0 values
R0 = plyr::ldply(sgs, function(x) {
  data.frame(r0 = c(params(x)["a"] * params(x)["b"]))
})

# Set up parallel processing
ncores = max(1, detectCores() - 4)
cl = makeCluster(ncores)
registerDoParallel(cl)

# Fit Beverton-Holt models
bh1 = foreach(id = ids, .packages = c("FLCore", "FLBRP", "FLCandy", "FLRebuild")) %dopar% {
  try(FLCandy:::updateRefs(FLCandy::eql(icesdata[[id]], model = "bevholtSV")))
}
names(bh1) = ids

bh2 = foreach(id = ids, .packages = c("FLCore", "FLBRP", "FLCandy", "FLRebuild")) %dopar% {
  try(FLCandy:::updateRefs(FLCandy::eql(icesdata[[id]], model = "bevholtSV", 
      prior_s = fl[fl$.id == id, "s"], cv_s = 0.1)))
}
names(bh2) = ids

bh3 = foreach(id = ids, .packages = c("FLCore", "FLBRP", "FLCandy", "FLRebuild")) %dopar% {
  try(FLCandy:::updateRefs(FLCandy::eql(icesdata[[id]], model = "bevholtSV", 
      prior_r0 = R0[R0$.id == id, "r0"], cv_r0 = 0.1)))
}
names(bh3) = ids

# Fit Ricker models
rk1 = foreach(id = ids, .packages = c("FLCore", "FLBRP", "FLCandy", "FLRebuild")) %dopar% {
  try(FLCandy:::updateRefs(FLCandy::eql(icesdata[[id]], model = "rickerSV")))
}
names(rk1) = ids

rk2 = foreach(id = ids, .packages = c("FLCore", "FLBRP", "FLCandy", "FLRebuild")) %dopar% {
  try(FLCandy:::updateRefs(FLCandy::eql(icesdata[[id]], model = "rickerSV", 
      prior_s = fl[fl$.id == id, "s"], cv_s = 0.1)))
}
names(rk2) = ids

rk3 = foreach(id = ids, .packages = c("FLCore", "FLBRP", "FLCandy", "FLRebuild")) %dopar% {
  try(FLCandy:::updateRefs(FLCandy::eql(icesdata[[id]], model = "rickerSV", 
      prior_r0 = R0[R0$.id == id, "r0"], cv_r0 = 0.1)))
}
names(rk3) = ids

stopCluster(cl)

# Save equilibrium models
save(bh1, bh2, bh3, rk1, rk2, rk3, sgs, gms, bm, fl, R0, 
     file = file.path(vignetteDataDir, "eq.RData"))
```

### Reference Points and Nonstationarity

Calculate reference points for each stock-recruitment model scenario using 
nonstationarity analysis. This evaluates how reference points change over time 
given nonstationary biological parameters.

```{r, rf}
ids = names(icesdata)

# Set up parallel processing
ncores = max(1, detectCores() - 4)
cl = makeCluster(ncores)
registerDoParallel(cl)

# Calculate reference points for Beverton-Holt models
bh1rf = foreach(id = ids, .combine = rbind.fill,
        .packages = c("FLCore", "FLBRP", "FLCandy", "plyr")) %dopar% {
  try(cbind(.id = id, FLCandy:::nonStationarity(icesdata[[id]], bh1[[id]])))
}

bh2rf = foreach(id = ids, .combine = rbind,
        .packages = c("FLCore", "FLBRP", "FLCandy")) %dopar% {
  try(cbind(.id = id, FLCandy:::nonStationarity(icesdata[[id]], bh2[[id]])))
}

bh3rf = foreach(id = ids, .combine = rbind,
        .packages = c("FLCore", "FLBRP", "FLCandy")) %dopar% {
  try(cbind(.id = id, FLCandy:::nonStationarity(icesdata[[id]], bh3[[id]])))
}

# Calculate reference points for Ricker models
rk1rf = foreach(id = ids, .combine = rbind,
        .packages = c("FLCore", "FLBRP", "FLCandy")) %dopar% {
  try(cbind(.id = id, FLCandy:::nonStationarity(icesdata[[id]], rk1[[id]])))
}

rk2rf = foreach(id = ids, .combine = rbind,
        .packages = c("FLCore", "FLBRP", "FLCandy")) %dopar% {
  try(cbind(.id = id, FLCandy:::nonStationarity(icesdata[[id]], rk2[[id]])))
}

rk3rf = foreach(id = ids, .combine = rbind,
        .packages = c("FLCore", "FLBRP", "FLCandy")) %dopar% {
  try(cbind(.id = id, FLCandy:::nonStationarity(icesdata[[id]], rk3[[id]])))
}

stopCluster(cl)

# Combine all reference points
rf = rbind(
  cbind(SRR = "Beverton & Holt", rbind(
    cbind(Scenario = 1, bh1rf),
    cbind(Scenario = 2, bh2rf),
    cbind(Scenario = 3, bh3rf))),
  cbind(SRR = "Ricker", rbind(
    cbind(Scenario = 1, rk1rf),
    cbind(Scenario = 2, rk2rf),
    cbind(Scenario = 3, rk3rf))))

rf$Scenario = factor(rf$Scenario, 
                     labels = c("h & R0 Estimated", "Steepness Prior", "R0 Fixed"))

# Save reference points
save(rf, file = file.path(vignetteDataDir, "rf.RData"))
```

### Process Error

Process error represents the inherent variability in population dynamics that is 
not accounted for by the model structure. It differs from sampling error, which 
arises from the data collection process. However, it can be difficult to consistently 
identify the correct process error structure. Incorrectly attributing process error to 
the wrong model component (e.g. natural mortality vs selectivity) can lead to 
biased estimates and management advice.

```{r, pe}
ids = names(bh1)

# Set up parallel processing
ncores = max(1, detectCores() - 4)
cl = makeCluster(ncores)
registerDoParallel(cl)

# Calculate process error for Beverton-Holt models
bh1pe = foreach(id = ids, .combine = rbind.fill,
        .packages = c("FLCore", "FLBRP", "FLCandy", "dplyr")) %dopar% {
  try(cbind(.id = id, model.frame(processError(bh1[[id]]), drop = TRUE)))
}

bh2pe = foreach(id = ids, .combine = rbind,
        .packages = c("FLCore", "FLBRP", "FLCandy", "plyr")) %dopar% {
  try(cbind(.id = id, model.frame(processError(bh2[[id]]), drop = TRUE)))
}

bh3pe = foreach(id = ids, .combine = rbind.fill,
        .packages = c("FLCore", "FLBRP", "FLCandy", "dplyr")) %dopar% {
  try(cbind(.id = id, model.frame(processError(bh3[[id]]), drop = TRUE)))
}

# Calculate process error for Ricker models
rk1pe = foreach(id = ids, .combine = rbind,
        .packages = c("FLCore", "FLBRP", "FLCandy", "dplyr")) %dopar% {
  try(cbind(.id = id, model.frame(processError(rk1[[id]]), drop = TRUE)))
}

rk2pe = foreach(id = ids, .combine = rbind,
        .packages = c("FLCore", "FLBRP", "FLCandy", "dplyr")) %dopar% {
  try(cbind(.id = id, model.frame(processError(rk2[[id]]), drop = TRUE)))
}

rk3pe = foreach(id = ids, .combine = rbind,
        .packages = c("FLCore", "FLBRP", "FLCandy", "dplyr")) %dopar% {
  try(cbind(.id = id, model.frame(processError(rk3[[id]]), drop = TRUE)))
}

stopCluster(cl)

# Combine all process error results
pe = rbind(
  cbind(SRR = "Beverton & Holt", rbind(
    cbind(Scenario = 1, bh1pe),
    cbind(Scenario = 2, bh2pe),
    cbind(Scenario = 3, bh3pe))),
  cbind(SRR = "Ricker", rbind(
    cbind(Scenario = 1, rk1pe),
    cbind(Scenario = 2, rk2pe),
    cbind(Scenario = 3, rk3pe))))

pe$Scenario = factor(pe$Scenario, 
                     labels = c("h & R0 Estimated", "Steepness Prior", "R0 Fixed"))

# Save process error results
save(pe, file = file.path(vignetteDataDir, "pe.RData"))
```

### Time Series

Extract time series statistics for all stocks including catch, exploitable biomass, 
SSB, fishing mortality, harvest rate, and mean natural mortality.

```{r, ts}
ts = tseries(icesdata)
  
# Save to vignette data directory
save(ts, file = file.path(vignetteDataDir, "ts.RData"))
```

## Session Info

```{r, session-info}
sessionInfo()
```

